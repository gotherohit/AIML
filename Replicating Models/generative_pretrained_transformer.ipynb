{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative PreTrained Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Data/wine_review/winemag-data-130k-v2.json\") as data:\n",
    "    wine_review = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129971\n",
      "{'points': '87', 'title': 'Kirkland Signature 2011 Mountain Cuvée Cabernet Sauvignon (Napa Valley)', 'description': 'Soft, supple plum envelopes an oaky structure in this Cabernet, supported by 15% Merlot. Coffee and chocolate complete the picture, finishing strong at the end, resulting in a value-priced wine of attractive flavor and immediate accessibility.', 'taster_name': 'Virginie Boone', 'taster_twitter_handle': '@vboone', 'price': 19, 'designation': 'Mountain Cuvée', 'variety': 'Cabernet Sauvignon', 'region_1': 'Napa Valley', 'region_2': 'Napa', 'province': 'California', 'country': 'US', 'winery': 'Kirkland Signature'}\n"
     ]
    }
   ],
   "source": [
    "print(len(wine_review))\n",
    "print(wine_review[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_review = []\n",
    "for i in wine_review:\n",
    "    if i[\"country\"] is not None and i[\"province\"] is not None and i[\"variety\"] is not None and i[\"description\"] is not None:\n",
    "        update = \"Wine Review : \" + i['country'] + \" : \" + i[\"province\"] + \" : \" + i[\"variety\"] + \" : \" + i[\"description\"]\n",
    "        cleaned_review.append(update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punc_padding(sentence):\n",
    "    sentence = re.sub(f\"([{string.punctuation},'\\n'])\",r\" \\1 \",sentence)\n",
    "    sentence = re.sub(\" +\",\" \", sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc_padded_review = [punc_padding(x) for x in cleaned_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "N_HEADS = 2\n",
    "KEY_DIM = 256\n",
    "DENSE_DIM = 256\n",
    "EMBEDDING_DIM = 512\n",
    "STRING_LENGTH = 80\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "SHUFFLE_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tensor = tf.data.Dataset.from_tensor_slices(punc_padded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tensor = review_tensor.batch(BATCH_SIZE).shuffle(SHUFFLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower\",\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=STRING_LENGTH + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(review_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(81,), dtype=int64, numpy=\n",
       "array([   7,   10,    2,   20,    2,   29,    2,   45,   44,    2,   68,\n",
       "          3,  431,   67,    1,   52,  309,  120,   17,   12,   45,    3,\n",
       "       1007,   47,  660,   48,  100,    4,  212,    5,  107, 1158,    6,\n",
       "       2187,    3,  512,  305,   88,    6,  329,    3, 1928,   17,    8,\n",
       "        651,   14,  990,    7,    9,  232,  145,    5, 1410, 7537,    4,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0], dtype=int64)>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer(punc_padded_review[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(data):\n",
    "    data = tf.expand_dims(data,-1)\n",
    "    vectorize_data = vectorize_layer(data)\n",
    "    train_x = vectorize_data[:,:-1]\n",
    "    train_y = vectorize_data[:,1:]\n",
    "    return train_x, train_y\n",
    "train_dataset = review_tensor.map(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_check = train_dataset.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 80), dtype=int64, numpy=\n",
       "array([[ 7, 10,  2, ...,  0,  0,  0],\n",
       "       [ 7, 10,  2, ...,  0,  0,  0],\n",
       "       [ 7, 10,  2, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 7, 10,  2, ...,  0,  0,  0],\n",
       "       [ 7, 10,  2, ...,  0,  0,  0],\n",
       "       [ 7, 10,  2, ...,  0,  0,  0]], dtype=int64)>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input\n",
    "dataset_check[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE CAUSAL MASK SO THAT TOKEN LATER IN SEQUENCE DOESNOT IMPACT THE RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_causal_mask(batch_size, target,source,dtype = tf.int32):\n",
    "    query_range = tf.range(target)[:,None] # Expand the dimension to make it like row in matrix\n",
    "    key_range   = tf.range(source)\n",
    "    # Now we will create 1 and  0 mask of size query_range * key_range\n",
    "    mask = query_range >= key_range - source + target\n",
    "    mask = tf.cast(mask, dtype = dtype)\n",
    "    mask = tf.reshape(mask,[1,target,source])\n",
    "    # Now we need to expand the mask across batch\n",
    "    tile_dimension = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0) # for our use case we can do [batch_size,1,1]\n",
    "    return tf.tile(mask,tile_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[1, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [1, 1, 1, 1, 1]])>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_causal_mask(10,5,5,dtype = tf.int32)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE TRANSFORMER BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_head , k_dim , embed_dim , dense_dim , drop_out_rate=0.1):\n",
    "        super(TransformerBlock,self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.k_dim = k_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.drop_out_rate = drop_out_rate\n",
    "        self.m_h_attention = tf.keras.layers.MultiHeadAttention(n_head, k_dim, output_shape=embed_dim)\n",
    "        self.ln_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.ln_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dense1 = tf.keras.layers.Dense(self.dense_dim,activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(self.embed_dim)\n",
    "        self.drop1  = tf.keras.layers.Dropout(drop_out_rate)\n",
    "        self.drop2 = tf.keras.layers.Dropout(drop_out_rate)\n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        sequence_length = input_shape[1]\n",
    "        batch_size = input_shape[0]\n",
    "        causal_mask = create_causal_mask(batch_size, sequence_length,sequence_length,dtype = tf.bool)\n",
    "        x_attention, x_score = self.m_h_attention(inputs,inputs,attention_mask=causal_mask, return_attention_scores=True)\n",
    "        x_attention = self.drop1(x_attention)\n",
    "        x = self.ln_1(inputs + x_attention)\n",
    "        out = self.dense1(x)\n",
    "        out = self.dense2(out)\n",
    "        out = self.drop2(out)\n",
    "        return (self.ln_2(x + out),x_score)\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "            \"n_head\" : self.n_head,\n",
    "            \"k_dim\"  : self.k_dim,\n",
    "            \"embed_dim\" : self.embed_dim,\n",
    "            \"drop_out_rate\" : self.drop_out_rate,\n",
    "            \"dense_dim\" : self.dense_dim\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POSITIONAL ENCODING WITH EMBEDDING LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_positional_embedding(tf.keras.layers.Layer):\n",
    "    def __init__(self,embed_dim, vocab_size, max_length):\n",
    "        super(Text_positional_embedding,self).__init__()\n",
    "        self.embed_dim =embed_dim\n",
    "        self.vocab_size =vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.embed1 = tf.keras.layers.Embedding(input_dim=self.vocab_size, output_dim=self.embed_dim)\n",
    "        self.embed2 = tf.keras.layers.Embedding(input_dim=self.max_length, output_dim=self.embed_dim)\n",
    "    def call(self, inputs):\n",
    "        x = self.embed1(inputs)\n",
    "        y = self.embed2(tf.range(start=0,limit = tf.shape(inputs)[-1],delta=1))\n",
    "        return x + y\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"embed_dim\" : self.embed_dim,\n",
    "                \"vocab_size\" : self.vocab_size,\n",
    "                \"max_length\" : self.max_length\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORMER MODEL WITH 1 BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(None,), dtype=tf.int32)\n",
    "x = Text_positional_embedding(EMBEDDING_DIM,VOCAB_SIZE,STRING_LENGTH)(inputs)\n",
    "x, attention_scores = TransformerBlock(\n",
    "    n_head = N_HEADS, k_dim=KEY_DIM, embed_dim=EMBEDDING_DIM,dense_dim= DENSE_DIM\n",
    ")(x)\n",
    "outputs = tf.keras.layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "gpt = tf.keras.models.Model(inputs=inputs, outputs=[outputs, attention_scores])\n",
    "gpt.compile(\"adam\", loss=[tf.keras.losses.SparseCategoricalCrossentropy(), None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_positional_embedding_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,160,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Text_positional_embedding</span>)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_13            │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,584</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)] │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_14 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ text_positional_embedding_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m5,160,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mText_positional_embedding\u001b[0m)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_13            │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),    │     \u001b[38;5;34m1,315,584\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)] │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)    │     \u001b[38;5;34m5,130,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,606,544</span> (44.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,606,544\u001b[0m (44.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,606,544</span> (44.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,606,544\u001b[0m (44.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, index_to_word, top_k=10):\n",
    "        self.index_to_word = index_to_word\n",
    "        self.word_to_index = {\n",
    "            word: index for index, word in enumerate(index_to_word)\n",
    "        }\n",
    "\n",
    "    def sample_from(self, probs, temperature):\n",
    "        probs = probs ** (1 / temperature)\n",
    "        probs = probs / np.sum(probs)\n",
    "        return np.random.choice(len(probs), p=probs), probs\n",
    "\n",
    "    def generate(self, start_prompt, max_tokens, temperature):\n",
    "        start_tokens = [\n",
    "            self.word_to_index.get(x, 1) for x in start_prompt.split()\n",
    "        ]\n",
    "        sample_token = None\n",
    "        info = []\n",
    "        while len(start_tokens) < max_tokens and sample_token != 0:\n",
    "            x = np.array([start_tokens])\n",
    "            y, att = self.model.predict(x, verbose=0)\n",
    "            sample_token, probs = self.sample_from(y[0][-1], temperature)\n",
    "            info.append(\n",
    "                {\n",
    "                    \"prompt\": start_prompt,\n",
    "                    \"word_probs\": probs,\n",
    "                    \"atts\": att[0, :, -1, :],\n",
    "                }\n",
    "            )\n",
    "            start_tokens.append(sample_token)\n",
    "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
    "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
    "        return info\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.generate(\"wine review\", max_tokens=80, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./Data/checkpoint.weights.h5\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "# Tokenize starting prompt\n",
    "text_generator = TextGenerator(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 2.6011\n",
      "generated text:\n",
      "wine review : us : california : zinfandel : fantastically ripe blackberry jam and dark chocolate flavors are enveloped in ripe tannins . in this zinfandel , feels melted with moderate tannins and more concentration that acidity and dusty tannins . yet are a little tannic and dry . \n",
      "\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5671s\u001b[0m 3s/step - loss: 2.6009\n",
      "Epoch 2/5\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 1.9348\n",
      "generated text:\n",
      "wine review : france : bordeaux : bordeaux - style red blend : fruity and fruity , this structured wine also has a mix of perfumed berry fruit flavors by acidity that balance things . a solid core of good energy goes right . there is a tarry structure , solid tannins and concentrated acidity keep this structured with age for 3–4 years . \n",
      "\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6143s\u001b[0m 3s/step - loss: 1.9348\n",
      "Epoch 3/5\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 1.8492\n",
      "generated text:\n",
      "wine review : us : california : white blend : tight , unique and earthy , this wine sourced from itata and 40 - year - old vines were planted in [UNK] in dutton ranch . it ' s a big , bold , exuberant fruit - powered palate , both tannins , body , with a [UNK] of overripe kick on the finish . it combines with interesting citrus and pepper acidity , tamari and mozzarella . \n",
      "\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6130s\u001b[0m 3s/step - loss: 1.8492\n",
      "Epoch 4/5\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 1.7916\n",
      "generated text:\n",
      "wine review : italy : tuscany : sangiovese : this is the kind of red wine , a blend of canaiolo and colorino that shows an unusual nose backed by a gritty mouthfeel and power , with a bright core of red plum . shows a velvety mouthfeel , heavy berry flavors that of exotic spice and finally would pair beautifully with weighty ravioli stuffed mushrooms . \n",
      "\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6245s\u001b[0m 3s/step - loss: 1.7916\n",
      "Epoch 5/5\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 1.7488\n",
      "generated text:\n",
      "wine review : spain : northern spain : tempranillo : a riper wine with pastry aromas that are bit jumbled . but the cranberry shows some hard , sweaty , slightly overripe berry and earth notes . there ' s plenty of cedary oak and obtuse , burnt , while the flavors don ' t fully integrate . \n",
      "\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5922s\u001b[0m 3s/step - loss: 1.7488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x157e5d73990>"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[model_checkpoint_callback, tensorboard_callback, text_generator]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to save the model and reuse it for prediction later follow below steps. To make sure proper deserealization pass ** kwargs in custom class __init__() method like in Transformer, Text and Positional embedding class and then to super()__init__(** kwargs)\n",
    "so that base class can take care of additional name parameter given to custom class while deserealization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.save(\"./saved_model/gpt1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects = { 'Text_positional_embedding': Text_positional_embedding, 'TransformerBlock': TransformerBlock }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt1 = tf.keras.models.load_model(\"./saved_model/gpt1.keras\",custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some Random prediction to test the proper deserialization \n",
    "x =np.array([[2,1,3,4]])\n",
    "gpt1.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
